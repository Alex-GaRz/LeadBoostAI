
#üìÑ BLUEPRINT_FASE6_MEMORY.md: MEMORIA CORPORATIVA & FEEDBACK LOOP| Metadatos | Detalle |
| --- | --- |
| **Proyecto** | LeadBoostAI - Phoenix V5 |
| **Fase** | **FASE 6 - CORPORATE MEMORY (RAG)** |
| **Objetivo** | Implementar el almacenamiento de experiencias (Triadas Contexto-Acci√≥n-Resultado) y recuperaci√≥n estrat√©gica. |
| **Ubicaci√≥n** | `microservice_memory/` |
| **Stack** | Python 3.11, ChromaDB (Vector), OpenAI Embeddings (`text-embedding-3-small`). |
| **Estado** | `APPROVED FOR CONSTRUCTION` |

---

##1. Visi√≥n Arquitect√≥nicaLa memoria no es un simple log de base de datos. Es un **Motor RAG (Retrieval-Augmented Generation)** activo.
El sistema opera bajo el concepto de **Triada Normalizada**:

1. **Contexto:** ¬øQu√© intent√°bamos hacer? (Objetivo, Audiencia, Restricciones).
2. **Acci√≥n:** ¬øQu√© hicimos? (Estrategia, Copy, Artefactos).
3. **Resultado:** ¬øQu√© pas√≥? (KPIs, Auditor√≠a, Errores).

El servicio `microservice_memory` es **pasivo y determinista**: solo almacena cuando se le ordena (estado `LEARN`) y solo recupera cuando se le pregunta (antes de `STRATEGY_GEN`).

---

##2. Esquema de Datos H√≠brido (Memory Schema)Definimos los modelos de datos que extender√°n la `shared_lib`. Estos modelos se utilizan para estructurar lo que se guarda en ChromaDB (Metadata) y lo que se vectoriza.

###2.1 Modelo de Entrada de Memoria (`MemoryEntry`)```python
# shared_lib/contracts/memory.py (Propuesto) or microservice_memory/models/schemas.py

from pydantic import BaseModel, Field
from typing import Dict, List, Optional
from uuid import UUID
from datetime import datetime
from .enums import CampaignState, QualityVerdict

class MemoryMetrics(BaseModel):
    """Resultados duros de la ejecuci√≥n."""
    spend: float = 0.0
    impressions: int = 0
    clicks: int = 0
    conversions: int = 0
    ctr: float = 0.0
    roas: float = 0.0
    quality_score: int = 0 # 0-100 (Audit Score)

class ContextCard(BaseModel):
    """
    Representaci√≥n CAN√ìNICA para vectorizaci√≥n.
    Este texto es lo que se convierte en embeddings.
    """
    summary_text: str # "Campa√±a LinkedIn para CTOs, tono formal, objetivo leads, Q3 2024..."
    tags: List[str]   # ["B2B", "High-Budget", "Video"]

class MemoryEntry(BaseModel):
    """
    La unidad at√≥mica de memoria.
    """
    memory_id: str = Field(..., description="UUID √∫nico de la memoria")
    tenant_id: str
    execution_id: str
    campaign_id: str
    
    # Metadatos Estructurados (Filtros SQL-like)
    platform: str
    objective: str
    creation_date: datetime
    final_state: CampaignState
    quality_verdict: QualityVerdict
    
    # Data Rica (Payloads completos)
    strategy_summary: Dict # Resumen del StrategyBrief
    creative_summary: Dict # Resumen de Visual/Copy
    metrics: MemoryMetrics
    
    # Vectorizaci√≥n
    context_card: ContextCard
    
    class Config:
        arbitrary_types_allowed = True

```

---

##3. Motor de Vectorizaci√≥n (Embedding Strategy)###3.1 Stack Tecnol√≥gico* **Vector Store:** **ChromaDB**. Ejecut√°ndose en contenedor Docker persistente.
* *Justificaci√≥n:* Ya existe en la estructura del repo, es ligero, open-source y f√°cil de manejar localmente para desarrollo antes de escalar a pgvector/Pinecone.


* **Modelo de Embeddings:** `text-embedding-3-small` (OpenAI).
* *Justificaci√≥n:* Excelente relaci√≥n costo/calidad para comprensi√≥n sem√°ntica multiling√ºe.
* *Fallback:* `all-MiniLM-L6-v2` (SentenceTransformers) para modo offline/tests.



###3.2 Estrategia de "Chunking" (Canonicalizaci√≥n)**NO usaremos chunking tradicional** (dividir texto cada 500 caracteres). Eso destruye el contexto de una campa√±a.
Usaremos **Context Cards Generativas**:

Antes de insertar, el sistema genera un string denso y estructurado:

> "CAMPA√ëA B2B. Tenant: TechCorp. Objetivo: Leads. Audiencia: Gerentes TI en Latam. Tono: Autoritario. Canal: LinkedIn Ads. Resultado: ROAS 3.5 (Alto). Calidad: PASS. Resumen: Uso de infograf√≠a t√©cnica sobre ciberseguridad."

Este p√°rrafo entero se convierte en un **√∫nico vector**. Esto permite b√∫squedas sem√°nticas como: *"Campa√±as exitosas en LinkedIn para audiencias t√©cnicas"* y el vector coincidir√° por cercan√≠a sem√°ntica.

---

##4. Arquitectura del Servicio (`microservice_memory`)###4.1 √Årbol de Directorios```text
microservice_memory/
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ config.py             # Configuraci√≥n (Chroma Path, API Keys)
‚îÇ   ‚îú‚îÄ‚îÄ vector_store.py       # Wrapper de ChromaDB (Singleton)
‚îÇ   ‚îú‚îÄ‚îÄ embedding_engine.py   # Cliente OpenAI/Local
‚îÇ   ‚îú‚îÄ‚îÄ canonizer.py          # L√≥gica para crear "Context Cards" desde Payloads
‚îÇ   ‚îî‚îÄ‚îÄ ingestion.py          # Orquestador de guardado (Calcula KPIs finales)
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îú‚îÄ‚îÄ routes.py             # Endpoints FastAPI
‚îÇ   ‚îî‚îÄ‚îÄ dependencies.py       # Inyecci√≥n de dependencias
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ memory_models.py      # Pydantic Schemas internos
‚îú‚îÄ‚îÄ main.py                   # Entrypoint
‚îî‚îÄ‚îÄ requirements.txt

```

###4.2 Definici√≥n de Endpoints####`POST /ingest`Guarda una ejecuci√≥n finalizada.

* **Input:** `CampaignPayload` (Estado `LEARN` o `FAILED`).
* **L√≥gica:**
1. Validar que el estado sea terminal.
2. Extraer m√©tricas del Payload (si existen en `execution_logs` o un campo futuro de `metrics`).
3. `canonizer.create_card(payload)` -> Genera texto resumen.
4. `embedding_engine.embed(text)` -> Genera vector.
5. `vector_store.add(vector, metadata, id)`.


* **Output:** `{"memory_id": "...", "status": "stored"}`

####`POST /retrieve`Busca evidencia hist√≥rica para informar una nueva estrategia.

* **Input:**
```json
{
  "tenant_id": "uuid",
  "query_text": "Lanzamiento de producto SaaS B2B en Mexico",
  "filters": {
    "platform": "LINKEDIN",
    "min_quality": "PASS"
  },
  "limit": 3
}

```


* **L√≥gica:**
1. Generar embedding del `query_text`.
2. Ejecutar b√∫squeda h√≠brida en ChromaDB:
* `where={"tenant_id": "...", "platform": "LINKEDIN"}` (Filtro duro).
* `query_embeddings=[vector]` (Similitud sem√°ntica).


3. Retornar los Top-K resultados m√°s cercanos.


* **Output:** Lista de `MemoryEntry` (sin el payload crudo gigante, solo res√∫menes y m√©tricas).

---

##5. Integraci√≥n (The Feedback Loop)El Orquestador es quien controla cu√°ndo se aprende y cu√°ndo se recuerda.

###5.1 Diagrama A: Recuperaci√≥n (Antes de Pensar)*Estado Orquestador: `STRATEGY_GEN` (Inicio)*

```mermaid
sequenceDiagram
    participant ORCH as Orchestrator
    participant MEM as Memory Service
    participant ANA as Analyst Service

    Note over ORCH: Nueva Campa√±a Solicitada
    
    ORCH->>MEM: POST /retrieve (Query Contextual)
    Note right of ORCH: "Busca campa√±as previas similares\npara este Tenant y Objetivo"
    
    MEM-->>ORCH: 200 OK (Lista de 3 campa√±as pasadas)
    
    Note over ORCH: Inyecta memorias en CampaignPayload
    
    ORCH->>ANA: POST /generate_strategy (Payload + Memories)
    Note right of ANA: El Analista usa la memoria para\nNO repetir errores y copiar √©xitos.

```

###5.2 Diagrama B: Aprendizaje (Al Finalizar)*Estado Orquestador: `LEARN*`

```mermaid
sequenceDiagram
    participant ORCH as Orchestrator
    participant ACT as Actuator Service
    participant MEM as Memory Service

    Note over ORCH: Estado PUBLISH finalizado
    
    ORCH->>ACT: GET /metrics (Opcional: Obtener datos finales)
    ACT-->>ORCH: M√©tricas (Spend, Clicks)
    
    ORCH->>ORCH: Actualiza Payload con M√©tricas
    ORCH->>ORCH: Transition -> LEARN
    
    ORCH->>MEM: POST /ingest (CampaignPayload Final)
    
    MEM->>MEM: 1. Canonizar (Crear Context Card)
    MEM->>MEM: 2. Vectorizar (OpenAI)
    MEM->>MEM: 3. Persistir (ChromaDB)
    
    MEM-->>ORCH: 200 OK (MemoryID)
    
    ORCH->>ORCH: Transition -> IDLE / DONE

```

---

##6. Reglas de Implementaci√≥n Cr√≠ticas1. **Aislamiento de Tenants (Partition Key):**
* Cada consulta a ChromaDB **DEBE** incluir obligatoriamente el filtro `where={"tenant_id": request.tenant_id}`.
* **Riesgo:** Si esto falla, un cliente ver√° las estrategias de otro. Esto es un fallo de seguridad nivel cr√≠tico.


2. **No Alucinaci√≥n en Recuperaci√≥n:**
* El servicio de memoria devuelve datos crudos hist√≥ricos. No intenta resumirlos ni interpretarlos. La interpretaci√≥n es trabajo del `Analyst` en la siguiente fase. La memoria es "Facts only".


3. **Manejo de Fallos:**
* Si OpenAI Embeddings falla, el sistema debe reintentar (backoff).
* Si ChromaDB est√° ca√≠do, la operaci√≥n de `/retrieve` debe fallar suavemente (retornar lista vac√≠a) para no bloquear la creaci√≥n de campa√±as, pero `/ingest` debe encolar el reintento para no perder datos (Data Loss).


4. **Inmutabilidad:**
* Una vez escrita una memoria (`memory_id`), su contenido sem√°ntico (lo que pas√≥) no cambia. Solo se pueden actualizar m√©tricas si llegan datos tard√≠os (atribuci√≥n retardada).



---

##Pasos Siguientes para el Ingeniero1. **Refactorizar `microservice_memory`:** Limpiar el c√≥digo actual para adoptar esta estructura estricta.
2. **Implementar `Canonizer`:** Crear la l√≥gica que convierte un JSON complejo en un string narrativo denso.
3. **Configurar Chroma:** Asegurar que `docker-compose.yml` levanta ChromaDB con persistencia de volumen.
4. **Tests:** Crear tests que simulen la ingesta de 2 campa√±as y verifiquen que la b√∫squeda por similitud devuelve la correcta.